# day211116 - Deep Learning

## What is Deep Learning

Deep learning is a subset of machine learning

Machine Learning involves teaching computers to recognize patterns in data

In Deep Learning, features can be learned just from raw data!

Neural Networks

Take in data as input

Train themselves to understand patterns in the data

Output useful predictions

Learning Process

**Forward Propagation**

propagation from the input layer to the output layer

And the input values are multiplied to the weights. And this sum will be passed through a non-linear function called the activation function which decides which particular neuron can contribute to the next layer

Terms

Weight - how important is that neuron

Bias - allows for the shifting of the activation to the right or left

In output layer it is a form of probability (prediction)

**Back Propagation:**

It is almost like the Forward Propagation. except in the reverse 

There is a question mark. Why would we have to pass the prediction (final output) back to the Input layer??

The output spits out two ways, right or wrong. That is where the neural network works the most. If it is wrong, the network uses something called a loss function to quantify the deviation(differences between the expected result and the predicted output) from the expected output. And this information is sent back to the hidden layers for the weights and biases to be adjusted

**Learning Algorithm**

Initialize Parameters with random values

Feed input data to the network

Compare the predicted value with the expected value & calculate the loss

Perform Backpropagation to propagate this loss back through the network

Update Parameters based on the loss

Iterate previous steps till loss is minimized

**Terms Used in Neural Networks**

Activation Functions

Introduce Non-Linearity in the Network

Decide whether a neuron can contribute to the next layer

But how do we know to decide if a neuron can fire/activate or not?