# day211005 - p-value

**Intro**

Since we can't conclude with a small number of samples, we need as many samples as we could get.

The more samples are, the more accurate and reliable the statistics get.

But given that no study is perfect and there are always a few random things that happen, how confident can we be that Drug A is superior?

That is where p-values come in...

**P-values**

p-values are numbers between 0 and 1, quantify how confident we should be that Sample A is different from Sample B

How small does a p-value have to be before we are sufficiently confident that Sample A is different from Sample B?

→ What threshold can we use to make a good decision?

In practice, a commonly used threshold is 0.05. It means that if there is no difference between Sample A and Sample B, and if we did this exact same experiment a bunch of times, then only 5% of those experiments would result in the wrong decision.

**False Positive**

In statistics, when performing multiple comparisons, a false positive ratio (also known as fall-out or false alarm ratio) is **the probability of falsely rejecting the null hypothesis for a particular test**. ... The false positive rate (or "false alarm rate") usually refers to the expectancy of the false positive ratio.

**Hypothesis Testing**

The idea of trying to determine if these drugs are the same or not is called Hypothesis Testing

**Things to make straight**

a small p-value does not imply that the effect size, or difference between Drug A and Drug B, is large