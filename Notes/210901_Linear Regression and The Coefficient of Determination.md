# Statistics_day210831=7

### Correlation is not Causation

Beware of lurking variables - correlation is not necessarily causation!

## Linear Regression and the Coefficient of Determination

### Least-Squares Criterion

"least-squares line"

The vertical distances between the dot and line are squared to get rid of the negative sign

These are called squares

The line belongs where it would cause the smallest sum of squares for the whole dataset

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1d481f3d-70c9-4be3-a8a0-199db96e6fac/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/01f75003-2b75-4093-9a4b-78a31a06208d/Untitled.png)

Goal: Fill in b and a so you have the least-squares line equation.

### Predicting with the Least Squares Line Equation

The slope (b) of the least-squares line tells us how many units the response variable (y) is expected to change for each 1 unit of change in the explanatory variable (x)

The number of units change in the y for each unit change in x is called the "marginal change" in the y

### What is the "Residual"?

In statistical models, a residual is the difference between the observed value and the mean value that the model predicts for that observation. Residual values are especially useful in regression and ANOVA procedures because they indicate the extent to which a model accounts for the variation in the observed data.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e306ca8b-04d9-4844-b8b8-e8f9ca5d8104/Untitled.png)

### Coefficient of Determination

The coefficient of determination is a statistical measurement that examines how differences in one variable can be explained by the difference in a second variable, when predicting the outcome of a given event.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a3288c92-5d25-4afe-935d-c17e20cb8cae/Untitled.png)